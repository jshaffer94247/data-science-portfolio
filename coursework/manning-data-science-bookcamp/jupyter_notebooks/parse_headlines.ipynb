{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manning Publications: Data Science Bookcamp\n",
    "    \n",
    "## Case Study 3: Tracking Disease Outbreaks Using News Headlines\n",
    "\n",
    "### Part 1: Extracting city and country names from news headlines\n",
    "\n",
    "                                                 2020 Jamie Shaffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: read in headlines.txt\n",
    "#       extract city and country names using regex and the names in the geonamescache library\n",
    "#       put them in a pandas DataFrame\n",
    "#  headline   city    country\n",
    "\n",
    "# Watch out for:\n",
    "#  Multiple city names in a headline\n",
    "#  Matches on short words (San) when it is part of a longer word (San Diego)\n",
    "#  Accents and diacritical markings (use unidecode)\n",
    "#  \n",
    "# PLUS my discoveries: headlines are in English\n",
    "#  Watch out for common English words that are also city names: 'Of' is a prime example\n",
    "\n",
    "# TODO\n",
    "#   A review of the output parsed_headlines.csv indicates that there are \n",
    "#   quite a few cities and/or\n",
    "#   regions that are not in geonamescache. Options: \n",
    "#       create my own list of names to cover these\n",
    "#       help with the geonamescache project\n",
    "#   About 7 of the headlines have BOTH city and country; if we don't resolve \n",
    "#       country names until later, remember to remove the duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'re'  version is  2.2.1\n",
      "'pandas'  version is  0.25.0\n",
      "'geonamescache'  version is  1.1.0\n"
     ]
    }
   ],
   "source": [
    "import re                         # 2.2.1\n",
    "import pandas as pd               # 0.25.0\n",
    "import geonamescache              # 1.1.0\n",
    "#import unidecode                  # has no __version__\n",
    "from unidecode import unidecode\n",
    "\n",
    "# PEP 484 type hints are easier with this\n",
    "from typing import Tuple\n",
    "\n",
    "for library in [re,pd,geonamescache]:\n",
    "    libname = (str(library)).split()[1]\n",
    "    print(libname,\" version is \",library.__version__)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBALS\n",
    "\n",
    "# For debugging, set this to 1\n",
    "debug = 0\n",
    "\n",
    "# Headlines that we will use are in this file; there are 650\n",
    "fname = \"../../../../discovering-disease-outbreaks-base/data/headlines.txt\"\n",
    "\n",
    "# First step when using geonamescache\n",
    "gc = geonamescache.GeonamesCache()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_headlines(fname:str)->list:\n",
    "    '''Input: fname - path to the file with the headlines, one per line\n",
    "       Output: headlines - a list of the headlines with minor processing:\n",
    "           \\n removed \n",
    "           unidecode used to remove accents and special characters\n",
    "    '''\n",
    "    with open(fname,'r') as f1:\n",
    "        headlines = f1.read().splitlines()  # creates a list of headlines with \\n removed\n",
    "\n",
    "    # Just in case they came in with special chars, unidecode the headlines:\n",
    "    for h in range(0,len(headlines)):\n",
    "        headlines[h] = unidecode(headlines[h])\n",
    "        \n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_city_list()->pd.DataFrame:\n",
    "    '''Read in the cities and put them in a simplified dataframe for easy access\n",
    "       GLOBALS used: gc\n",
    "    '''\n",
    "\n",
    "    # gc_countries = gc.get_countries()\n",
    "    gc_cities    = gc.get_cities()\n",
    "\n",
    "    df_cities = pd.DataFrame(columns=['original_name','geonameid','latitude','longitude','countrycode'])\n",
    "\n",
    "    for c in gc_cities:\n",
    "        df_cities = df_cities.append({'original_name':gc_cities[c]['name'], \\\n",
    "                                  'geonameid':c,\\\n",
    "                                  'latitude':gc_cities[c]['latitude'],\\\n",
    "                                  'longitude': gc_cities[c]['longitude'],\\\n",
    "                                  'countrycode':gc_cities[c]['countrycode']},\\\n",
    "                         ignore_index=True)\n",
    "\n",
    "    # Tidy up the names\n",
    "\n",
    "    df_cities['tidy_name'] = df_cities['original_name'].apply(lambda x: unidecode(x)) # 4904 names are affected\n",
    "\n",
    "    # Sort the cities so that the longer ones come first\n",
    "    df_cities['tidy_len'] = df_cities['tidy_name'].apply(lambda x: len(x))\n",
    "    df_cities.sort_values(by='tidy_len',ascending=False,inplace=True)\n",
    "    \n",
    "    len_original = len(df_cities)\n",
    "    \n",
    "    # Drop the tricky ones\n",
    "    # A smarter algo might be able to figure out if they meant the city, but this is the less smart version for now\n",
    "    tricky_cities = ['Of','Gap','Boom','Hit','Can','Man','Goes','Come','Bay','Spring','Borne','Buy',\\\n",
    "                    'Bury','Bra','Papa']\n",
    "    \n",
    "    df_cities.drop(df_cities.loc[df_cities['tidy_name'].isin(tricky_cities)].index, inplace=True)\n",
    "    \n",
    "    len_final = len(df_cities)\n",
    "    \n",
    "    print(\"df_cities original: {} and final: {}\".format(len_original,len_final))\n",
    "    \n",
    "    return df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_list()->pd.DataFrame:\n",
    "    '''Read in the countries and put them in a simplified dataframe for easy access\n",
    "       GLOBALS used: gc\n",
    "    '''\n",
    "    gc_countries = gc.get_countries()\n",
    "    # gc_cities    = gc.get_cities()\n",
    "\n",
    "    df_countries = pd.DataFrame(columns=['original_name','geonameid','countrycode'])\n",
    "\n",
    "    for c in gc_countries:\n",
    "        df_countries = df_countries.append({'original_name':gc_countries[c]['name'], \\\n",
    "                                  'geonameid':c,\\\n",
    "                                  'countrycode':gc_countries[c]['iso']},\\\n",
    "                         ignore_index=True)\n",
    "\n",
    "    # Tidy up the names\n",
    "\n",
    "    df_countries['tidy_name'] = df_countries['original_name'].apply(lambda x: unidecode(x)) # 4904 names are affected\n",
    "\n",
    "    # Sort the cities so that the longer ones come first\n",
    "    df_countries['tidy_len'] = df_countries['tidy_name'].apply(lambda x: len(x))\n",
    "    df_countries.sort_values(by='tidy_len',ascending=False,inplace=True)\n",
    "    \n",
    "    return df_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lines(search_term: str, clean_list: list, hack_list: list, \\\n",
    "                isCity = True) -> Tuple[pd.DataFrame, list]:\n",
    "    '''Look for the search_term in the clean_list\n",
    "       When found, add the line and the term to a pd.DataFrame\n",
    "           if isCity is True, add as a City, otherwise add as a Country\n",
    "       Remove the search_term from that line in the hack_list so substrings won't match it\n",
    "       Return the pd.DataFrame when all done\n",
    "       \n",
    "       Example:\n",
    "         clean_list entry             'Zika Outbreak Hits Miami'\n",
    "            leads to hack_list entry  'Zika Outbreak Hits   '\n",
    "    '''\n",
    "    df_found = pd.DataFrame(columns=['headline','city'])\n",
    "    \n",
    "    uni_search = r'\\b' + unidecode(search_term) + r'\\b'\n",
    "    #print(\"uni_search is: \",uni_search)\n",
    "    regexp = re.compile(uni_search,flags=re.IGNORECASE)\n",
    "    \n",
    "    count = 0\n",
    "    for hnum in range(0,len(clean_list),1):\n",
    "        \n",
    "        h1 = hack_list[hnum]\n",
    "        h2 = clean_list[hnum]\n",
    "        \n",
    "        if regexp.search(h1):\n",
    "            count = count + 1\n",
    "            if (isCity):\n",
    "                df_found = df_found.append({'headline':h2,'city':search_term}, ignore_index=True)\n",
    "            else:\n",
    "                df_found = df_found.append({'headline':h2,'country':search_term}, ignore_index=True)\n",
    "            hack_list[hnum] = regexp.sub(\"  \", hack_list[hnum])\n",
    "            if (debug):\n",
    "                print(\"Match line {}: {} is in {} so the hack is now {}\".format(hnum,\\\n",
    "                                                                            uni_search,\\\n",
    "                                                                            clean_list[hnum],\\\n",
    "                                                                            hack_list[hnum]))\n",
    "    \n",
    "    return df_found, hack_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = fetch_headlines(fname)\n",
    "\n",
    "if (debug):\n",
    "    print(type(headlines))\n",
    "    #print(headlines)\n",
    "    print(headlines[2])\n",
    "    \n",
    "len(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cities original: 24336 and final: 24321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "original_name    4900\n",
       "geonameid        4900\n",
       "latitude         4900\n",
       "longitude        4900\n",
       "countrycode      4900\n",
       "tidy_name        4900\n",
       "tidy_len         4900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities = prepare_city_list()\n",
    "(df_cities[df_cities['original_name'] != df_cities['tidy_name']]).count()  \n",
    "# 4904 names were affected in the original list; now that I'm removing the tricky ones, the count may be lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_name    0\n",
       "geonameid        0\n",
       "countrycode      0\n",
       "tidy_name        0\n",
       "tidy_len         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries = prepare_country_list()\n",
    "(df_countries[df_countries['original_name'] != df_countries['tidy_name']]).count()  # 0 names are affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cities)\n",
    "\n",
    "# Is \"Of\" a real city? If so, I need to learn some geography!\n",
    "df_cities.to_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>tidy_name</th>\n",
       "      <th>tidy_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16758</th>\n",
       "      <td>Chak Two Hundred Forty-nine Thal Development A...</td>\n",
       "      <td>1179305</td>\n",
       "      <td>31.17772</td>\n",
       "      <td>71.20480</td>\n",
       "      <td>PK</td>\n",
       "      <td>Chak Two Hundred Forty-nine Thal Development A...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>Dolores Hidalgo Cuna de la Independencia Nacional</td>\n",
       "      <td>4023117</td>\n",
       "      <td>21.15611</td>\n",
       "      <td>-100.93250</td>\n",
       "      <td>MX</td>\n",
       "      <td>Dolores Hidalgo Cuna de la Independencia Nacional</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15048</th>\n",
       "      <td>Ampliación San Mateo (Colonia Solidaridad)</td>\n",
       "      <td>8858118</td>\n",
       "      <td>19.61639</td>\n",
       "      <td>-99.14722</td>\n",
       "      <td>MX</td>\n",
       "      <td>Ampliacion San Mateo (Colonia Solidaridad)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15033</th>\n",
       "      <td>Licenciado Benito Juárez (Campo Gobierno)</td>\n",
       "      <td>8858101</td>\n",
       "      <td>24.65667</td>\n",
       "      <td>-107.54500</td>\n",
       "      <td>MX</td>\n",
       "      <td>Licenciado Benito Juarez (Campo Gobierno)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>Sant Pere, Santa Caterina i La Ribera</td>\n",
       "      <td>3119123</td>\n",
       "      <td>41.38450</td>\n",
       "      <td>2.18152</td>\n",
       "      <td>ES</td>\n",
       "      <td>Sant Pere, Santa Caterina i La Ribera</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_name geonameid  latitude  \\\n",
       "16758  Chak Two Hundred Forty-nine Thal Development A...   1179305  31.17772   \n",
       "15007  Dolores Hidalgo Cuna de la Independencia Nacional   4023117  21.15611   \n",
       "15048         Ampliación San Mateo (Colonia Solidaridad)   8858118  19.61639   \n",
       "15033          Licenciado Benito Juárez (Campo Gobierno)   8858101  24.65667   \n",
       "6530               Sant Pere, Santa Caterina i La Ribera   3119123  41.38450   \n",
       "\n",
       "       longitude countrycode  \\\n",
       "16758   71.20480          PK   \n",
       "15007 -100.93250          MX   \n",
       "15048  -99.14722          MX   \n",
       "15033 -107.54500          MX   \n",
       "6530     2.18152          ES   \n",
       "\n",
       "                                               tidy_name  tidy_len  \n",
       "16758  Chak Two Hundred Forty-nine Thal Development A...        54  \n",
       "15007  Dolores Hidalgo Cuna de la Independencia Nacional        49  \n",
       "15048         Ampliacion San Mateo (Colonia Solidaridad)        42  \n",
       "15033          Licenciado Benito Juarez (Campo Gobierno)        41  \n",
       "6530               Sant Pere, Santa Caterina i La Ribera        37  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>tidy_name</th>\n",
       "      <th>tidy_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>South Georgia and the South Sandwich Islands</td>\n",
       "      <td>GS</td>\n",
       "      <td>GS</td>\n",
       "      <td>South Georgia and the South Sandwich Islands</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>United States Minor Outlying Islands</td>\n",
       "      <td>UM</td>\n",
       "      <td>UM</td>\n",
       "      <td>United States Minor Outlying Islands</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bonaire, Saint Eustatius and Saba</td>\n",
       "      <td>BQ</td>\n",
       "      <td>BQ</td>\n",
       "      <td>Bonaire, Saint Eustatius and Saba</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heard Island and McDonald Islands</td>\n",
       "      <td>HM</td>\n",
       "      <td>HM</td>\n",
       "      <td>Heard Island and McDonald Islands</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>VC</td>\n",
       "      <td>VC</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_name geonameid countrycode  \\\n",
       "89   South Georgia and the South Sandwich Islands        GS          GS   \n",
       "232          United States Minor Outlying Islands        UM          UM   \n",
       "29             Bonaire, Saint Eustatius and Saba         BQ          BQ   \n",
       "95              Heard Island and McDonald Islands        HM          HM   \n",
       "237              Saint Vincent and the Grenadines        VC          VC   \n",
       "\n",
       "                                        tidy_name  tidy_len  \n",
       "89   South Georgia and the South Sandwich Islands        44  \n",
       "232          United States Minor Outlying Islands        36  \n",
       "29             Bonaire, Saint Eustatius and Saba         34  \n",
       "95              Heard Island and McDonald Islands        33  \n",
       "237              Saint Vincent and the Grenadines        32  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(columns=['headline','city','country'])\n",
    "\n",
    "# Shorten headlines for debugging\n",
    "if (debug):\n",
    "    headlines = headlines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping 2 versions of the headline:\n",
    "# headlines -- untouched, handy for quoting the headline, and we'll need it at the end\n",
    "# hack_headlines -- every time a match is found, hack it out so a smaller substring can't match it later\n",
    "hack_headlines = headlines.copy()  # this will be butchered by the time we're done, so we can look at it to see what was missed\n",
    "\n",
    "for c in df_cities['tidy_name']:\n",
    "    df_out, hack_headlines = check_lines(c,clean_list = headlines, hack_list = hack_headlines, isCity = True)\n",
    "    \n",
    "    df_final = df_final.append(df_out,sort=False)  # sort=True changes the order of columns and is the default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking headline lists: original 650 and hacked 650 lines.\n"
     ]
    }
   ],
   "source": [
    "# Did the list of headlines get mangled?\n",
    "print(\"Checking headline lists: original {} and hacked {} lines.\".format(len(headlines),len(hack_headlines)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_countries['tidy_name']:\n",
    "    df_out, hack_headlines = check_lines(c,clean_list = headlines, hack_list = hack_headlines, isCity = False)\n",
    "    \n",
    "    df_final = df_final.append(df_out,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Zika Outbreak Hits Miami', 'Zika Outbreak Hits   ')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0], hack_headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking headline lists: original 650 and hacked 650 lines.\n"
     ]
    }
   ],
   "source": [
    "# Did the list of headlines get mangled?\n",
    "print(\"Checking headline lists: original {} and hacked {} lines.\".format(len(headlines),len(hack_headlines)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a visual check -- this was handy when I was only working with the first 10 or so lines\n",
    "if (debug):\n",
    "    for c in range(0,len(headlines)):      # hack_headlines < headlines  -- some did not have any city data?\n",
    "        print(\"{}     vs       {}\".format(headlines[c],hack_headlines[c]))\n",
    "    \n",
    "# Zip them together into a dataframe and write it out for easier comparison offline\n",
    "df_check = pd.DataFrame(list(zip(headlines,hack_headlines)),columns=['OriginalHeadline','GeoNamesHackedOut'])\n",
    "df_check.to_csv('check_headline_hacks.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking headline lists: original 650 and hacked 650 lines.\n"
     ]
    }
   ],
   "source": [
    "# Did the list of headlines get mangled?\n",
    "print(\"Checking headline lists: original {} and hacked {} lines.\".format(len(headlines),len(hack_headlines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pedro Juan Caballero Encounters Severe Symptoms of Pneumonia</td>\n",
       "      <td>Pedro Juan Caballero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rumors about Hepatitis D Spreading in San Juan Capistrano have been Refuted</td>\n",
       "      <td>San Juan Capistrano</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zika Spreads to Palm Beach Gardens</td>\n",
       "      <td>Palm Beach Gardens</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zika Reported in North Miami Beach</td>\n",
       "      <td>North Miami Beach</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zika cases in Vietnam's Ho Chi Minh City surge</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      headline                  city country\n",
       "0  Pedro Juan Caballero Encounters Severe Symptoms of Pneumonia                 Pedro Juan Caballero  NaN   \n",
       "0  Rumors about Hepatitis D Spreading in San Juan Capistrano have been Refuted  San Juan Capistrano   NaN   \n",
       "0  Zika Spreads to Palm Beach Gardens                                           Palm Beach Gardens    NaN   \n",
       "0  Zika Reported in North Miami Beach                                           North Miami Beach     NaN   \n",
       "0  Zika cases in Vietnam's Ho Chi Minh City surge                               Ho Chi Minh City      NaN   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many headlines did we keep from the original 650?\n",
    "df_final['headline'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dropped - no city or country: Louisiana Zika cases up to 26\n",
      "2 Dropped - no city or country: Zika infects pregnant woman in Cebu\n",
      "3 Dropped - no city or country: Spanish Flu Sighted in Antigua\n",
      "4 Dropped - no city or country: Zika case reported in Oton\n",
      "5 Dropped - no city or country: Hillsborough uses innovative trap against Zika 20 minutes ago\n",
      "6 Dropped - no city or country: Maka City Experiences Influenza Outbreak\n",
      "7 Dropped - no city or country: West Nile Virus Outbreak in Saint Johns\n",
      "8 Dropped - no city or country: Malaria Exposure in Sussex\n",
      "9 Dropped - no city or country: Greenwich Establishes Zika Task Force\n",
      "10 Dropped - no city or country: Will West Nile Virus vaccine help Parsons?\n",
      "11 Dropped - no city or country: Yulee takes a hit from Spreading Sickness\n",
      "12 Dropped - no city or country: The Spread of Chikungunya in Davidson has been Confirmed\n",
      "13 Dropped - no city or country: Zika case reported in Los Fresnos\n",
      "14 Dropped - no city or country: More people in Boucau are infected with HIV every year\n",
      "15 Dropped - no city or country: Bronchitis Outbreak in Manhasset\n",
      "16 Dropped - no city or country: Zika Troubles come to Padre Las Casas\n",
      "17 Dropped - no city or country: Rumors about Influenza Spreading in Dobbs Ferry have been Refuted\n",
      "18 Dropped - no city or country: Outbreak of Zika in Destin\n",
      "19 Dropped - no city or country: More people in Huron are infected with Dengue every year\n",
      "20 Dropped - no city or country: Will Tuberculosis vaccine help Cherry Creek?\n",
      "21 Dropped - no city or country: Gympie Patient in Critical Condition after Contracting Chlamydia\n",
      "22 Dropped - no city or country: Spike of Meningitis Cases in Druid Hills\n",
      "23 Dropped - no city or country: Martinsville tests new cure for Measles\n",
      "24 Dropped - no city or country: More Patients in Magnolia are Getting Diagnosed with Malaria\n",
      "25 Dropped - no city or country: Rumors about Syphilis spreading in Penal have been refuted\n",
      "26 Dropped - no city or country: Fort Belvoir tests new cure for Hepatitis C\n",
      "27 Dropped - no city or country: More people in Oak Brook are infected with Respiratory Syncytial Virus every year\n",
      "28 Dropped - no city or country: Outbreak of Zika in Hutchins\n",
      "29 Dropped - no city or country: Longwood volunteers spreading Zika awareness\n",
      "30 Dropped - no city or country: Zika symptoms spotted in Quixere\n",
      "31 Dropped - no city or country: Measles Hits Davos\n",
      "32 Dropped - no city or country: Spike of Hepatitis E Cases in Morehead City\n",
      "33 Dropped - no city or country: Outbreak of Zika in Alvorada\n",
      "34 Dropped - no city or country: Schools in Coamo Closed Due to Rhinovirus Outbreak\n",
      "35 Dropped - no city or country: Zika arrives in Dangriga\n",
      "36 Dropped - no city or country: More Patients in Maynard are Getting Diagnosed with Syphilis\n",
      "37 Dropped - no city or country: Zika case reported in Antioquia\n",
      "38 Dropped - no city or country: Chikungunya has not Left Pismo Beach\n",
      "39 Dropped - no city or country: Zika spreads to La Joya\n"
     ]
    }
   ],
   "source": [
    "# Sanity check -- which headlines did not end up in the final frame?\n",
    "if (1):\n",
    "    count_drops = 0\n",
    "    for c in range(0,len(headlines)):      # hack_headlines < headlines  -- some did not have any city data?\n",
    "        if (headlines[c] == hack_headlines[c]):\n",
    "            count_drops += 1\n",
    "            print(\"{} Dropped - no city or country: {}\".format(count_drops,headlines[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pedro Juan Caballero Encounters Severe Symptoms of Pneumonia</td>\n",
       "      <td>Pedro Juan Caballero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rumors about Hepatitis D Spreading in San Juan Capistrano have been Refuted</td>\n",
       "      <td>San Juan Capistrano</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zika Spreads to Palm Beach Gardens</td>\n",
       "      <td>Palm Beach Gardens</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zika Reported in North Miami Beach</td>\n",
       "      <td>North Miami Beach</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zika cases in Vietnam's Ho Chi Minh City surge</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      headline                  city country\n",
       "0  Pedro Juan Caballero Encounters Severe Symptoms of Pneumonia                 Pedro Juan Caballero  NaN   \n",
       "1  Rumors about Hepatitis D Spreading in San Juan Capistrano have been Refuted  San Juan Capistrano   NaN   \n",
       "2  Zika Spreads to Palm Beach Gardens                                           Palm Beach Gardens    NaN   \n",
       "3  Zika Reported in North Miami Beach                                           North Miami Beach     NaN   \n",
       "4  Zika cases in Vietnam's Ho Chi Minh City surge                               Ho Chi Minh City      NaN   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.index = range(0,df_final.shape[0])\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"parsed_headlines.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
